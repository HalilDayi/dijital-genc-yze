{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:29:58.200848Z",
     "start_time": "2024-07-16T12:29:57.267043Z"
    }
   },
   "source": [
    "import pandas\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from w1_utils import sub_dataframe, generate_class_labels, test_data_classification, introduce_nans, report_completeness, test_data_regression"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:29:58.236660Z",
     "start_time": "2024-07-16T12:29:58.202915Z"
    }
   },
   "source": [
    "source_file = \"ankara_23v4.csv\"\n",
    "\n",
    "nan_row_ratio = 0.99\n",
    "nan_ratio = 0.99\n",
    "nan_border = 0.0\n",
    "\n",
    "ankara_data = pandas.read_csv(source_file)\n",
    "ankara_data.head()\n",
    "\n",
    "report_completeness(ankara_data)\n",
    "print(\"------------------------\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "------------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:29:58.286436Z",
     "start_time": "2024-07-16T12:29:58.238169Z"
    }
   },
   "source": [
    "print(ankara_data.columns)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'S1_PM10', 'S1_PM25', 'S1_SO2', 'S1_NO2', 'S1_NOX',\n",
      "       'S1_NO', 'S2_PM10', 'S2_PM25', 'S2_SO2', 'S2_CO', 'S2_03', 'S5_PM10',\n",
      "       'S5_CO', 'S7_PM10', 'S9_PM10', 'S9_SO2', 'S9_NO2', 'S9_NOX', 'S9_NO',\n",
      "       'S10_PM10', 'S10_PM25', 'S10_CO', 'S11_PM10', 'S12_CO', 'S13_PM10',\n",
      "       'S13_PM25', 'S13_SO2', 'S14_PM10', 'S14_PM25', 'S14_SO2', 'S14_NO2',\n",
      "       'S14_NOX', 'S14_NO', 'S15_PM10', 'S15_SO2', 'S15_NO2', 'S15_NOX',\n",
      "       'S15_NO', 'S15_O3', 'S17_PM10', 'S17_PM25', 'S17_SO2', 'S17_NO2',\n",
      "       'S17_NOX', 'S17_NO', 'S17_O3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:29:58.475037Z",
     "start_time": "2024-07-16T12:29:58.288950Z"
    }
   },
   "source": [
    "s1_data = sub_dataframe(df=ankara_data, station='S1')\n",
    "s2_data = sub_dataframe(df=ankara_data, station='S2')\n",
    "s9_data = sub_dataframe(df=ankara_data, station='S9')\n",
    "s14_data = sub_dataframe(df=ankara_data, station='S14')\n",
    "s15_data = sub_dataframe(df=ankara_data, station='S15')\n",
    "s17_data = sub_dataframe(df=ankara_data, station='S17')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:30:02.268967Z",
     "start_time": "2024-07-16T12:29:58.476379Z"
    }
   },
   "source": [
    "# Hadi Eksik Veri YaratalÄ±m\n",
    "\n",
    "s1_data_org = s1_data.copy()\n",
    "s2_data_org = s2_data.copy()\n",
    "s9_data_org = s9_data.copy()\n",
    "s14_data_org = s14_data.copy()\n",
    "s15_data_org = s15_data.copy()\n",
    "s17_data_org = s17_data.copy()\n",
    "\n",
    "s1_data_nanned = introduce_nans(df=s1_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "s2_data_nanned = introduce_nans(df=s2_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "s9_data_nanned = introduce_nans(df=s9_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "s14_data_nanned = introduce_nans(df=s14_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "s15_data_nanned = introduce_nans(df=s15_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "s17_data_nanned = introduce_nans(df=s17_data, row_ratio= nan_row_ratio, ratio=nan_ratio,  border=nan_border)\n",
    "\n",
    "s1_data_nanned.to_csv(\"temp/nanned.csv\")\n",
    "s1_data_org.to_csv(\"temp/org.csv\")\n",
    "\n",
    "data_collection = [[s1_data_nanned, s1_data_org],\n",
    "[s2_data_nanned, s2_data_org],\n",
    "[s9_data_nanned, s9_data_org],\n",
    "[s14_data_nanned, s14_data_org], \n",
    "[s15_data_nanned, s15_data_org],\n",
    "[s17_data_nanned, s17_data_org]]\n",
    "\n",
    "for data in data_collection:\n",
    "    report_completeness(df=data[0])\n",
    "    report_completeness(df=data[1])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 17.619854550589565 - COMP ROW: 54 - COMP ROW PERC%: 1.1438254607074771\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "Overall: 20.779495869519167 - COMP ROW: 46 - COMP ROW PERC%: 0.9743698368989621\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "Overall: 20.96589705570854 - COMP ROW: 57 - COMP ROW PERC%: 1.2073713196356703\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "Overall: 17.602202923109516 - COMP ROW: 53 - COMP ROW PERC%: 1.122643507731413\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "Overall: 17.496293158229193 - COMP ROW: 47 - COMP ROW PERC%: 0.9955517898750263\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n",
      "Overall: 15.102732471933905 - COMP ROW: 45 - COMP ROW PERC%: 0.9531878839228977\n",
      "Overall: 100.0 - COMP ROW: 4721 - COMP ROW PERC%: 100.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:30:03.805033Z",
     "start_time": "2024-07-16T12:30:02.270456Z"
    }
   },
   "source": [
    "export_enabled = True\n",
    "\n",
    "if export_enabled:\n",
    "    exp_s1_data = generate_class_labels(s1_data_org)\n",
    "    exp_s2_data = generate_class_labels(s2_data_org)\n",
    "    exp_s9_data = generate_class_labels(s9_data_org)\n",
    "    exp_s14_data = generate_class_labels(s14_data_org)\n",
    "    exp_s15_data = generate_class_labels(s15_data_org)\n",
    "    exp_s17_data = generate_class_labels(s17_data_org)\n",
    "\n",
    "    exp_s1_data.to_csv(\"exps_pre_augmentation/station_1.csv\")\n",
    "    exp_s2_data.to_csv(\"exps_pre_augmentation/station_2.csv\")\n",
    "    exp_s9_data.to_csv(\"exps_pre_augmentation/station_9.csv\")\n",
    "    exp_s14_data.to_csv(\"exps_pre_augmentation/station_14.csv\")\n",
    "    exp_s15_data.to_csv(\"exps_pre_augmentation/station_15.csv\")\n",
    "    exp_s17_data.to_csv(\"exps_pre_augmentation/station_17.csv\")\n",
    "\n",
    "    s1_data_nanned.to_csv(\"nanned_s1.csv\")\n",
    "    s2_data_nanned.to_csv(\"nanned_s2.csv\")\n",
    "    s9_data_nanned.to_csv(\"nanned_s9.csv\")\n",
    "    s14_data_nanned.to_csv(\"nanned_s14.csv\")\n",
    "    s15_data_nanned.to_csv(\"nanned_s15.csv\")\n",
    "    s17_data_nanned.to_csv(\"nanned_s17.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:30:47.268306Z",
     "start_time": "2024-07-16T12:30:03.806409Z"
    }
   },
   "source": [
    "results = []\n",
    "\n",
    "data_out = False\n",
    "regression_kernels = ['linear', 'rbf', 'poly']\n",
    "selected_kernel = regression_kernels[1]\n",
    "\n",
    "for active_data_tuple in data_collection:\n",
    "    # For each data, use missing value estimation methods separetely and get classification results\n",
    "\n",
    "    active_data = active_data_tuple[0]\n",
    "    original_data = generate_class_labels(active_data_tuple[1])\n",
    "    print(\"Label Counts: \" + str(original_data['OUT'].value_counts()))\n",
    "\n",
    "    # Drop NA\n",
    "    data_drop_na = active_data.dropna()\n",
    "    data_drop_na = generate_class_labels(df=data_drop_na)\n",
    "    acc_dropna = test_data_classification(df=data_drop_na, df_org=original_data, data_out=data_out)\n",
    "\n",
    "    # Mean Imputation \n",
    "    data_imputed_mean = active_data.copy()\n",
    "    for col in data_imputed_mean.columns:\n",
    "        data_imputed_mean[col] = data_imputed_mean[col].fillna(data_imputed_mean.loc[:,col].mean())\n",
    "    data_imputed_mean = generate_class_labels(df=data_imputed_mean)\n",
    "    acc_mean = test_data_classification(df=data_imputed_mean, df_org=original_data, data_out=data_out)\n",
    "\n",
    "    #print(\"Mean Shape\" + str(data_imputed_mean.shape))\n",
    "\n",
    "    # Zero Imputation \n",
    "    data_imputed_zero = active_data.copy()\n",
    "    for col in data_imputed_zero.columns:\n",
    "        data_imputed_zero[col] = data_imputed_zero[col].fillna(0)\n",
    "    data_imputed_zero = generate_class_labels(df=data_imputed_zero)\n",
    "    acc_zero = test_data_classification(df=data_imputed_zero, df_org=original_data, data_out=data_out)\n",
    "\n",
    "    #print(\"Zero Shape\" + str(data_imputed_mean.shape))\n",
    "\n",
    "    # Bfill Imputation\n",
    "    data_imputed_bfill = active_data.bfill().ffill()\n",
    "    data_imputed_bfill = generate_class_labels(df=data_imputed_bfill)\n",
    "    acc_bfill = test_data_classification(df=data_imputed_bfill, df_org=original_data, data_out=data_out)\n",
    "\n",
    "    #print(\"Bfill Shape\" + str(data_imputed_mean.shape))\n",
    "\n",
    "    # FFill Imputation\n",
    "    data_imputed_ffill = active_data.ffill().bfill()\n",
    "    data_imputed_ffill = generate_class_labels(df=data_imputed_ffill)\n",
    "    acc_ffill = test_data_classification(df=data_imputed_ffill, df_org=original_data, data_out=data_out)\n",
    "    #print(\"Ffill Shape\" + str(data_imputed_mean.shape))\n",
    "\n",
    "    # Interpolation Imputation\n",
    "    data_imputed_interpolation = active_data.interpolate().bfill().ffill()\n",
    "    data_imputed_interpolation = generate_class_labels(df=data_imputed_interpolation)\n",
    "    acc_interpolate = test_data_classification(df=data_imputed_interpolation, df_org=original_data, data_out=data_out)\n",
    "\n",
    "    #print(\"Inter Shape\" + str(data_imputed_mean.shape))\n",
    "\n",
    "    # KNN Imputation\n",
    "    #imputer = KNNImputer(n_neighbors=3)\n",
    "    #imputed = imputer.fit_transform(active_data)\n",
    "    #data_imputed_knn = pandas.DataFrame(imputed, columns=active_data.columns),\n",
    "    #data_imputed_knn = generate_class_labels(df=data_imputed_knn)\n",
    "    #acc_knnimpute = test_data_classification(df=data_imputed_knn)\n",
    "\n",
    "    results.append({\"DROP\": round(acc_dropna,2), \n",
    "                    \"ZERO\": round(acc_zero,2), \n",
    "                    \"MEAN\": round(acc_mean,2), \n",
    "                    \"BFILL\": round(acc_bfill,2), \n",
    "                    \"FFILL\": round(acc_ffill,2), \n",
    "                    \"INTERPOLATE\": round(acc_interpolate,2)})\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "2    1959\n",
      "3    1731\n",
      "1     714\n",
      "4     315\n",
      "5       1\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "2    2326\n",
      "3    1160\n",
      "1    1029\n",
      "4     185\n",
      "5      20\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "2    2120\n",
      "1    1266\n",
      "3    1075\n",
      "4     259\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "2    1756\n",
      "1    1481\n",
      "3    1204\n",
      "4     274\n",
      "5       5\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "1    1892\n",
      "2    1854\n",
      "3     783\n",
      "4     182\n",
      "5       9\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: OUT\n",
      "2    1995\n",
      "3    1237\n",
      "1     765\n",
      "4     645\n",
      "5      78\n",
      "0       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metehanguzel/Desktop/projects/DDYM_PP_master/MissingData/Air_Quality/w1_utils.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"OUT\"] = AQIs[1:]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:30:47.273198Z",
     "start_time": "2024-07-16T12:30:47.269444Z"
    }
   },
   "source": [
    "for result in results:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DROP': 0.54, 'ZERO': 0.18, 'MEAN': 0.41, 'BFILL': 0.71, 'FFILL': 0.7, 'INTERPOLATE': 0.7}\n",
      "{'DROP': 0.48, 'ZERO': 0.22, 'MEAN': 0.49, 'BFILL': 0.78, 'FFILL': 0.78, 'INTERPOLATE': 0.78}\n",
      "{'DROP': 0.29, 'ZERO': 0.27, 'MEAN': 0.45, 'BFILL': 0.76, 'FFILL': 0.76, 'INTERPOLATE': 0.77}\n",
      "{'DROP': 0.16, 'ZERO': 0.31, 'MEAN': 0.37, 'BFILL': 0.72, 'FFILL': 0.71, 'INTERPOLATE': 0.71}\n",
      "{'DROP': 0.38, 'ZERO': 0.4, 'MEAN': 0.39, 'BFILL': 0.79, 'FFILL': 0.78, 'INTERPOLATE': 0.78}\n",
      "{'DROP': 0.38, 'ZERO': 0.16, 'MEAN': 0.26, 'BFILL': 0.74, 'FFILL': 0.74, 'INTERPOLATE': 0.75}\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
